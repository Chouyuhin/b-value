{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5032f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### select the reginal catolog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25bf7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def filter_by_lat_lon_time(\n",
    "    file_path: str,\n",
    "    lat_min: float,\n",
    "    lat_max: float,\n",
    "    lon_min: float,\n",
    "    lon_max: float,\n",
    "    start_time: str = None,\n",
    "    end_time: str = None,\n",
    "    output_path: str = \"filtered_data.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    从 txt 文件中筛选出指定经纬度和时间范围内的数据，并保存为 CSV 文件。\n",
    "\n",
    "    参数:\n",
    "        file_path (str): 输入的 txt 文件路径。\n",
    "        lat_min (float): 最小纬度。\n",
    "        lat_max (float): 最大纬度。\n",
    "        lon_min (float): 最小经度。\n",
    "        lon_max (float): 最大经度。\n",
    "        start_time (str, 可选): 起始时间（格式 'YYYY-MM-DD HH:MM:SS'）。\n",
    "        end_time (str, 可选): 结束时间（格式 'YYYY-MM-DD HH:MM:SS'）。\n",
    "        output_path (str): 输出的 CSV 文件路径。\n",
    "\n",
    "    返回:\n",
    "        pandas.DataFrame: 筛选后的数据。\n",
    "    \"\"\"\n",
    "\n",
    "    # 定义列名\n",
    "    columns = [\n",
    "        'year', 'month', 'day', 'hour', 'minute', 'second',\n",
    "        'latitude', 'longitude', 'anything', 'mag_type', 'magnitude'\n",
    "    ]\n",
    "\n",
    "    # 读取 txt 文件（空格分隔）\n",
    "    df = pd.read_csv(file_path, sep=r'\\s+', names=columns)\n",
    "\n",
    "    # 组合时间列\n",
    "    df['datetime'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute', 'second']])\n",
    "\n",
    "    # 经纬度筛选\n",
    "    filtered_df = df[\n",
    "        (df['latitude'] >= lat_min) & (df['latitude'] <= lat_max) &\n",
    "        (df['longitude'] >= lon_min) & (df['longitude'] <= lon_max)\n",
    "    ]\n",
    "\n",
    "    # 时间筛选\n",
    "    if start_time:\n",
    "        start_dt = pd.to_datetime(start_time)\n",
    "        filtered_df = filtered_df[filtered_df['datetime'] >= start_dt]\n",
    "\n",
    "    if end_time:\n",
    "        end_dt = pd.to_datetime(end_time)\n",
    "        filtered_df = filtered_df[filtered_df['datetime'] <= end_dt]\n",
    "\n",
    "    # 保存为 CSV 文件\n",
    "    filtered_df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"✅ 已将筛选结果保存到 {output_path}\")\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e0aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已将筛选结果保存到 region3_cal.csv\n",
      "      year  month  day  hour  minute  second  latitude  longitude  anything  \\\n",
      "1644  1970      3    3     8      22    44.0     26.25     103.15         0   \n",
      "1779  1970      3   16     7      44    58.0     26.03     102.45         0   \n",
      "1780  1970      3   16     7      46    46.0     26.05     102.48         0   \n",
      "1785  1970      3   16    11      51    32.0     26.03     102.48         0   \n",
      "1792  1970      3   17     4      47     3.0     26.30     102.20         0   \n",
      "\n",
      "     mag_type  magnitude  \n",
      "1644       ML        2.1  \n",
      "1779       ML        3.4  \n",
      "1780       ML        3.4  \n",
      "1785       ML        2.3  \n",
      "1792       ML        1.9  \n"
     ]
    }
   ],
   "source": [
    "result = filter_by_lat_lon(\n",
    "    file_path=\"/Users/chouyuhin/Desktop/CENCcat-format.txt\",\n",
    "    lat_min=26,\n",
    "    lat_max=26.4,\n",
    "    lon_min=102.15,\n",
    "    lon_max=103.55,\n",
    "    start_time=\"2020-01-01 00:00:00\",\n",
    "    end_time=\"2021-12-31 23:59:59\",\n",
    "    output_path=\"region3_cal.csv\"\n",
    ")\n",
    "\n",
    "print(result.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0bf31f",
   "metadata": {},
   "source": [
    "### 拼接standard catalog和我的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3372ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1455\n",
      "237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y4/__h0s0zj0qb4gjkjzynnyrcr0000gn/T/ipykernel_92961/2356758502.py:5: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  data = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from seismostats import Catalog\n",
    "\n",
    "data = pd.read_csv(\n",
    "    '/Users/chouyuhin/Desktop/hypoDD_v2_1329_withmag_modified_final.reloc',\n",
    "    delim_whitespace=True,\n",
    "    usecols=['lat', 'lon', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second', 'magnitude']\n",
    ")\n",
    "\n",
    "data['time'] = pd.to_datetime(data[['year', 'month', 'day', 'hour', 'minute', 'second']])\n",
    "# print(data['time']) \n",
    "data = data.rename(columns={'lat': 'latitude', 'lon': 'longitude'})\n",
    "data = data[['longitude', 'latitude', 'depth', 'time', 'magnitude']]\n",
    "data = data[data['time']>='2022-12-01 00:00:00']\n",
    "print(len(data))\n",
    "standard= pd.read_csv(\n",
    "    '/Users/chouyuhin/Desktop/standard_catalog_QJ_220825_230313.csv',\n",
    "    sep=',',\n",
    "    usecols=['year', 'month', 'day', 'hour', 'minute', 'second','latitude', 'longitude','depth', 'mag_type', 'magnitude','time']\n",
    " \n",
    ")\n",
    "standard = standard[['longitude', 'latitude', 'depth', 'time', 'magnitude']]\n",
    "standard = standard[standard['time']<='2022-12-01 00:00:00']\n",
    "print(len(standard))\n",
    "combined_data = pd.concat([data, standard], ignore_index=True)\n",
    "# combined_data = combined_data.sort_values(by='time').reset_index(drop=True)\n",
    "combined_data.to_csv('/Users/chouyuhin/Desktop/combined_test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ad77d3",
   "metadata": {},
   "source": [
    "### 将三个模型得到的reloc文件合并到一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c491380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# 假设你的 6 个 reloc 文件都放在同一个目录下，并且以 .reloc 结尾\n",
    "files = [\n",
    "    '/Users/chouyuhin/workhome/QJvalidation/eqt_2023raw/hypoDD_eqt2023raw_withmag.reloc',\n",
    "         '/Users/chouyuhin/workhome/QJvalidation/phasenet_2023raw/hypoDD_phasenet2023raw_withmag.reloc',\n",
    "         '/Users/chouyuhin/workhome/QJvalidation/tran_2023raw/hypoDD_tran2023raw_withmag.reloc',\n",
    "         '/Users/chouyuhin/workhome/QJvalidation/eqt_20228_11_raw/hypoDD_eqt2208_11raw_withmag.reloc',\n",
    "         '/Users/chouyuhin/Desktop/hypoDD_tran2208_11raw_withmag.reloc',\n",
    "         '/Users/chouyuhin/Desktop/hypoDD_tran2212raw_withmag.reloc']\n",
    "\n",
    "# 指定列名\n",
    "cols = ['lat', 'lon', 'depth', 'year', 'month', 'day', 'hour', 'minute', 'second', 'magnitude']\n",
    "\n",
    "# 读取并合并所有文件\n",
    "df_list = []\n",
    "for f in files:\n",
    "    df = pd.read_csv(f, sep=r\"\\s+\", usecols=cols, engine='python')\n",
    "    df_list.append(df)\n",
    "\n",
    "# 合并为一个总表\n",
    "data = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 创建时间列\n",
    "data['time'] = pd.to_datetime(\n",
    "    data[['year', 'month', 'day', 'hour', 'minute', 'second']]\n",
    ")\n",
    "\n",
    "# 按 time 升序排序\n",
    "data = data.sort_values('time').reset_index(drop=True)\n",
    "# data = data[data['magnitude'] != -1.0]\n",
    "# 导出为新的 reloc 文件\n",
    "data.to_csv(\"merged_reloc.reloc\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8150a16",
   "metadata": {},
   "source": [
    "### 处理，去掉重复记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f917d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成：已删除 magnitude=-1 且时间/深度重复的行。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取文件\n",
    "df = pd.read_csv(\"/Users/chouyuhin/_Workhome/Proj_Seismicgap/QJvalidation/hypoDD_final_allevents.reloc\", sep=\"\\t\")\n",
    "\n",
    "# 转换 time 列\n",
    "df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "\n",
    "# 强制转换所有数值列为 float（关键）\n",
    "num_cols = ['lat','lon','depth','year','month','day','hour','minute','second','magnitude']\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# 拆分 good 与 bad\n",
    "bad = df[df['magnitude'] == -1.0].copy()\n",
    "good = df[df['magnitude'] != -1.0].copy()\n",
    "\n",
    "good = good.sort_values('time')\n",
    "bad['to_delete'] = False\n",
    "\n",
    "# 遍历 bad 中每条记录\n",
    "for idx, row in bad.iterrows():\n",
    "    t0 = row['time']\n",
    "    d0 = row['depth']\n",
    "\n",
    "    # 时间窗口 ±1秒\n",
    "    mask_time = (good['time'] >= t0 - pd.Timedelta(seconds=3)) & \\\n",
    "                (good['time'] <=  t0 + pd.Timedelta(seconds=3))\n",
    "    candidates = good[mask_time]\n",
    "\n",
    "    if not candidates.empty:\n",
    "        # 深度差 ≤ 1 km\n",
    "        mask_depth = (candidates['depth'] - d0).abs() <= 5.0\n",
    "        if mask_depth.any():\n",
    "            bad.loc[idx, 'to_delete'] = True\n",
    "\n",
    "# 删除 bad 行\n",
    "bad_clean = bad[~bad['to_delete']]\n",
    "\n",
    "# 合并\n",
    "df_clean = pd.concat([good, bad_clean], ignore_index=True)\n",
    "\n",
    "# 排序\n",
    "df_clean = df_clean.sort_values('time').reset_index(drop=True)\n",
    "\n",
    "# 保存最终结果\n",
    "df_clean.to_csv(\"merged_reloc_clean.reloc\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"完成：已删除 magnitude=-1 且时间/深度重复的行。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
